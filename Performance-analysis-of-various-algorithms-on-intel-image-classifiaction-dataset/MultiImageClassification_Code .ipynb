{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as Layers\n",
    "import tensorflow.keras.activations as Activations\n",
    "import tensorflow.keras.models as Models\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "import keras \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import SVG\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest'] \n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}  \n",
    "nb_classes = len(class_names)  \n",
    "IMAGE_SIZE = (32, 32)\n",
    "IMAGE_SIZE1 = (150, 150)  \n",
    "# Image sizes used are different for different algoritms.\n",
    "# for NN and CNN and InceptionV3 and VGG are 150*150\n",
    "# for other algoritmhms is 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datasets = ['seg_train', 'seg_test']\n",
    "    output = []\n",
    "   \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "       \n",
    "        images = []\n",
    "        labels = []\n",
    "       \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "       \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "           \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "               \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "               \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "               \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "               \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')  \n",
    "        print(images.shape)\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data1():\n",
    "   \n",
    "    datasets = ['seg_train', 'seg_test']\n",
    "    output = []\n",
    "   \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "       \n",
    "        images = []\n",
    "        labels = []\n",
    "       \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "       \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "           \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "               \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "               \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE1)\n",
    "               \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "               \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')  \n",
    "        print(images.shape)\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                            | 71/2191 [00:00<00:02, 708.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seg_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2191/2191 [00:02<00:00, 769.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2271/2271 [00:03<00:00, 741.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2404/2404 [00:03<00:00, 793.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2512/2512 [00:03<00:00, 817.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2274/2274 [00:02<00:00, 822.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2382/2382 [00:03<00:00, 787.29it/s]\n",
      " 19%|███████████████▌                                                                | 85/437 [00:00<00:00, 848.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 32, 32, 3)\n",
      "Loading seg_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 437/437 [00:00<00:00, 805.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 474/474 [00:00<00:00, 770.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 553/553 [00:00<00:00, 836.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 525/525 [00:00<00:00, 806.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 823.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 501/501 [00:00<00:00, 781.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (X_test, y_test) = load_data()  \n",
    "X_train, y_train = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████                                                                        | 145/2191 [00:00<00:01, 1449.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seg_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2191/2191 [00:01<00:00, 1448.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2271/2271 [00:01<00:00, 1391.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2404/2404 [00:01<00:00, 1500.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2512/2512 [00:01<00:00, 1540.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2274/2274 [00:01<00:00, 1542.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2382/2382 [00:01<00:00, 1468.91it/s]\n",
      " 12%|█████████▌                                                                      | 52/437 [00:00<00:00, 515.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 150, 150, 3)\n",
      "Loading seg_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 437/437 [00:00<00:00, 723.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 474/474 [00:00<00:00, 733.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 553/553 [00:00<00:00, 805.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 525/525 [00:00<00:00, 790.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 806.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 501/501 [00:00<00:00, 776.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "(train_images1, train_labels1), (Xnn_test, ynn_test) = load_data1()  \n",
    "Xnn_train, ynn_train = shuffle(train_images1, train_labels1, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# scaling is done by dividing each value by 255 and each value will be in range 0 and 1\n",
    "# for CNN NN InceptionV3 and VGG input are 4D arrays\n",
    "# for others are 2D array\n",
    "\n",
    "Xnn_train = Xnn_train/255\n",
    "Xnn_test = Xnn_test/255\n",
    "print(Xnn_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],32*32*3) \n",
    "X_test = X_test.reshape(X_test.shape[0],32*32*3) \n",
    "X_train = X_train/255; \n",
    "X_test = X_test/255;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.486\n",
      "613.0998592376709\n"
     ]
    }
   ],
   "source": [
    "# Code for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tic = time.time()\n",
    "log_reg = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter = 10000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "predlr = log_reg.predict(X_test)\n",
    "print(accuracy_score(predlr,y_test))\n",
    "toc = time.time()\n",
    "LRtime = toc-tic\n",
    "print(LRtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43633333333333335\n",
      "0.5185930728912354\n"
     ]
    }
   ],
   "source": [
    "# code for naive bayes with linear \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "tic = time.time()\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train,y_train)\n",
    "prednb = NB.predict(X_test)\n",
    "print(accuracy_score(prednb,y_test))\n",
    "toc = time.time()\n",
    "NBtime = toc-tic\n",
    "print(NBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467\n",
      "1.1257996559143066\n"
     ]
    }
   ],
   "source": [
    "# code for naive bayes with gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "tic = time.time()\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train,y_train)\n",
    "predgnb = GNB.predict(X_test)\n",
    "print(accuracy_score(predgnb,y_test))\n",
    "toc = time.time()\n",
    "NBtime = toc-tic\n",
    "print(NBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414\n",
      "44.41193699836731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tic = time.time()\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "preddt = dt.predict(X_test)\n",
    "print(accuracy_score(preddt,y_test))\n",
    "toc = time.time()\n",
    "KNNtime = toc-tic\n",
    "print(KNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4036666666666667\n",
      "6.677317142486572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "tic = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train,y_train)\n",
    "predknn = knn.predict(X_test)\n",
    "print(accuracy_score(predknn,y_test))\n",
    "toc = time.time()\n",
    "KNNtime = toc-tic\n",
    "print(KNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "88/88 [==============================] - 17s 165ms/step - loss: 3.6778 - accuracy: 0.3298 - val_loss: 1.4906 - val_accuracy: 0.38622\n",
      "Epoch 2/16\n",
      "88/88 [==============================] - 5s 63ms/step - loss: 1.3986 - accuracy: 0.4788 - val_loss: 1.4866 - val_accuracy: 0.4450\n",
      "Epoch 3/16\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 1.3628 - accuracy: 0.4942 - val_loss: 1.3829 - val_accuracy: 0.4788\n",
      "Epoch 4/16\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 1.2976 - accuracy: 0.5147 - val_loss: 1.5242 - val_accuracy: 0.4699\n",
      "Epoch 5/16\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 1.2562 - accuracy: 0.5278 - val_loss: 1.2910 - val_accuracy: 0.5297\n",
      "Epoch 6/16\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 1.2176 - accuracy: 0.5433 - val_loss: 1.4056 - val_accuracy: 0.4820\n",
      "Epoch 7/16\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 1.2301 - accuracy: 0.5411 - val_loss: 1.4004 - val_accuracy: 0.4663\n",
      "Epoch 8/16\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 1.1261 - accuracy: 0.5791 - val_loss: 1.3326 - val_accuracy: 0.5094\n",
      "Epoch 9/16\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 1.1486 - accuracy: 0.5699 - val_loss: 1.3518 - val_accuracy: 0.5087\n",
      "Epoch 10/16\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 1.1007 - accuracy: 0.5928 - val_loss: 1.3831 - val_accuracy: 0.5230\n",
      "Epoch 11/16\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 1.0596 - accuracy: 0.6035 - val_loss: 1.3263 - val_accuracy: 0.5112\n",
      "Epoch 12/16\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 1.0996 - accuracy: 0.5871 - val_loss: 1.2960 - val_accuracy: 0.5269\n",
      "Epoch 13/16\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 1.0023 - accuracy: 0.6276 - val_loss: 1.4098 - val_accuracy: 0.5205\n",
      "Epoch 14/16\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 1.0015 - accuracy: 0.6307 - val_loss: 1.3062 - val_accuracy: 0.5269\n",
      "Epoch 15/16\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.9776 - accuracy: 0.6369 - val_loss: 1.3163 - val_accuracy: 0.5468\n",
      "Epoch 16/16\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.9820 - accuracy: 0.6343 - val_loss: 1.4825 - val_accuracy: 0.4877\n",
      "77.1002197265625\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "tic = time.time()\n",
    "model2 =Sequential([\n",
    "    tf.keras.layers.Flatten( input_shape = (150, 150, 3)),\n",
    "    tf.keras.layers.Dense(64*3, activation= 'relu' ),\n",
    "    tf.keras.layers.Dense(64, activation= 'relu' ),\n",
    "    tf.keras.layers.Dense(32, activation= 'relu' ),\n",
    "    tf.keras.layers.Dense(6, activation= 'softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(Xnn_train, ynn_train, batch_size=128, epochs=16, validation_split = 0.2)\n",
    "\n",
    "toc = time.time()\n",
    "NNtime = toc-tic\n",
    "print(NNtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 15ms/step - loss: 1.4893 - accuracy: 0.4633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4892703294754028, 0.4633333384990692]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(Xnn_test,ynn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "176/176 [==============================] - 23s 123ms/step - loss: 1.1142 - accuracy: 0.5893 - val_loss: 0.9522 - val_accuracy: 0.6245\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 16s 92ms/step - loss: 0.6762 - accuracy: 0.7494 - val_loss: 0.8055 - val_accuracy: 0.7086\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 16s 91ms/step - loss: 0.5338 - accuracy: 0.8060 - val_loss: 0.7215 - val_accuracy: 0.7531\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 16s 92ms/step - loss: 0.3940 - accuracy: 0.8589 - val_loss: 0.7306 - val_accuracy: 0.7471\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 16s 90ms/step - loss: 0.2381 - accuracy: 0.9219 - val_loss: 0.7474 - val_accuracy: 0.7923\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 16s 91ms/step - loss: 0.1415 - accuracy: 0.9582 - val_loss: 0.8320 - val_accuracy: 0.7895\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 16s 92ms/step - loss: 0.0932 - accuracy: 0.9731 - val_loss: 0.8900 - val_accuracy: 0.7734\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 16s 90ms/step - loss: 0.0516 - accuracy: 0.9898 - val_loss: 1.0282 - val_accuracy: 0.7748\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 15s 88ms/step - loss: 0.0342 - accuracy: 0.9934 - val_loss: 1.0809 - val_accuracy: 0.7809\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 15s 87ms/step - loss: 0.0310 - accuracy: 0.9952 - val_loss: 1.2191 - val_accuracy: 0.7859\n",
      "166.17591190338135\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(Xnn_train, ynn_train, batch_size=64, epochs=10, validation_split = 0.2)\n",
    "toc = time.time()\n",
    "CNNtime = toc-tic\n",
    "print(CNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 21ms/step - loss: 1.2042 - accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2042089700698853, 0.7749999761581421]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xnn_test,ynn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.5896666666666667\n",
      "18.951029777526855\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "import xgboost as xgb\n",
    "xg_cl = xgb.XGBClassifier(objective='multi:softprob',\n",
    "n_estimators=10, seed=123)\n",
    "xg_cl.fit(X_train, y_train)\n",
    "preds = xg_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(accuracy)\n",
    "toc = time.time()\n",
    "XGBtime = toc-tic\n",
    "print(XGBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.594\n",
      "52.458067655563354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tic = time.time()\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred=clf.predict(X_test)\n",
    "from sklearn import metrics  \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "toc = time.time()\n",
    "RFtime = toc-tic\n",
    "print(RFtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9283348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "tic = time.time()\n",
    "pca = PCA(n_components=500)\n",
    "pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497.737286567688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "predsvm = svm.predict(X_test)\n",
    "toc = time.time()\n",
    "svmtime = toc-tic\n",
    "print(svmtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6386666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predsvm))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
