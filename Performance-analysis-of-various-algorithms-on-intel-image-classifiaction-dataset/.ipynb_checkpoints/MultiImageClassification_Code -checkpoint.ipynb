{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as Layers\n",
    "import tensorflow.keras.activations as Activations\n",
    "import tensorflow.keras.models as Models\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "import keras \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import SVG\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest'] \n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}  \n",
    "nb_classes = len(class_names)  \n",
    "IMAGE_SIZE = (32, 32)\n",
    "IMAGE_SIZE1 = (150, 150)  \n",
    "# Image sizes used are different for different algoritms.\n",
    "# for NN and CNN size is 64*64\n",
    "# for InceptionV3 and VGG are 150*150\n",
    "# for other algoritmhms is 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n",
    "    output = []\n",
    "   \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "       \n",
    "        images = []\n",
    "        labels = []\n",
    "       \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "       \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "           \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "               \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "               \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "               \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "               \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')  \n",
    "        print(images.shape)\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data1():\n",
    "   \n",
    "    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n",
    "    output = []\n",
    "   \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "       \n",
    "        images = []\n",
    "        labels = []\n",
    "       \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "       \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "           \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "               \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "               \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE1)\n",
    "               \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "               \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')  \n",
    "        print(images.shape)\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (X_test, y_test) = load_data()  \n",
    "X_train, y_train = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images1, train_labels1), (Xnn_test, ynn_test) = load_data1()  \n",
    "Xnn_train, ynn_train = shuffle(train_images1, train_labels1, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling is done by dividing each value by 255 and each value will be in range 0 and 1\n",
    "# for CNN NN InceptionV3 and VGG input are 4D arrays\n",
    "# for others are 2D array\n",
    "\n",
    "Xnn_train = Xnn_train/255\n",
    "Xnn_test = Xnn_test/255\n",
    "print(Xnn_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],32*32*3) \n",
    "X_test = X_test.reshape(X_test.shape[0],32*32*3) \n",
    "X_train = X_train/255; \n",
    "X_test = X_test/255;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tic = time.time()\n",
    "log_reg = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter = 10000)\n",
    "log_reg.fit(X_train,y_train)\n",
    "predlr = log_reg.predict(X_test)\n",
    "print(accuracy_score(predlr,y_test))\n",
    "toc = time.time()\n",
    "LRtime = toc-tic\n",
    "print(LRtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for naive bayes with linear \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "tic = time.time()\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train,y_train)\n",
    "prednb = NB.predict(X_test)\n",
    "print(accuracy_score(prednb,y_test))\n",
    "toc = time.time()\n",
    "NBtime = toc-tic\n",
    "print(NBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for naive bayes with gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "tic = time.time()\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train,y_train)\n",
    "predgnb = GNB.predict(X_test)\n",
    "print(accuracy_score(predgnb,y_test))\n",
    "toc = time.time()\n",
    "NBtime = toc-tic\n",
    "print(NBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tic = time.time()\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "preddt = dt.predict(X_test)\n",
    "print(accuracy_score(preddt,y_test))\n",
    "toc = time.time()\n",
    "KNNtime = toc-tic\n",
    "print(KNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "tic = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train,y_train)\n",
    "predknn = knn.predict(X_test)\n",
    "print(accuracy_score(predknn,y_test))\n",
    "toc = time.time()\n",
    "KNNtime = toc-tic\n",
    "print(KNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "tic = time.time()\n",
    "model2 =Sequential([\n",
    "    keras.layers.Flatten( input_shape = (64,64,3)),\n",
    "    keras.layers.Dense(64*3, activation= 'relu' ),\n",
    "    keras.layers.Dense(64, activation= 'relu' ),\n",
    "    keras.layers.Dense(32, activation= 'relu' ),\n",
    "    keras.layers.Dense(6, activation= 'softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(Xnn_train, ynn_train, batch_size=128, epochs=16, validation_split = 0.2)\n",
    "\n",
    "toc = time.time()\n",
    "NNtime = toc-tic\n",
    "print(NNtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(Xnn_test,ynn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (64, 64, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(Xnn_train, ynn_train, batch_size=128, epochs=10, validation_split = 0.2)\n",
    "toc = time.time()\n",
    "CNNtime = toc-tic\n",
    "print(CNNtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xnn_test,ynn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "import xgboost as xgb\n",
    "xg_cl = xgb.XGBClassifier(objective='multi:softprob',\n",
    "n_estimators=10, seed=123)\n",
    "xg_cl.fit(X_train, y_train)\n",
    "preds = xg_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(accuracy)\n",
    "toc = time.time()\n",
    "XGBtime = toc-tic\n",
    "print(XGBtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tic = time.time()\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred=clf.predict(X_test)\n",
    "from sklearn import metrics  \n",
    "print(\"Accuracy:\",metrics.accuracy _score(y_test, y_pred))\n",
    "toc = time.time()\n",
    "RFtime = toc-tic\n",
    "print(RFtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "tic = time.time()\n",
    "pca = PCA(n_components=500)\n",
    "pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "predsvm = svm.predict(X_test)\n",
    "toc = time.time()\n",
    "svmtime = toc-tic\n",
    "print(svmtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predsvm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "local_weights_file = '/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "     layer.trainable = False\n",
    "        \n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "x = layers.Dense(6, activation='softmax')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "history=model.fit(Xnn_train,ynn_train,epochs=1,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xnn_test,ynn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "file='/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained_model=VGG16(input_shape = (150, 150, 3), \n",
    "                        include_top = False, \n",
    "                        weights =None)\n",
    "pretrained_model.load_weights(file)\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "     layer.trainable = False\n",
    "\n",
    "last_layer = pretrained_model.get_layer('block5_pool')\n",
    "print('last layer of vgg : output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "y = layers.Flatten()(last_output)\n",
    "y = layers.Dense(1024, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)                  \n",
    "y = layers.Dense(6, activation='softmax')(y)           \n",
    "\n",
    "model_vgg = Model(pretrained_model.input, y) \n",
    "\n",
    "\n",
    "model_vgg.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.fit(Xnn_train,ynn_train,epochs=1,validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
